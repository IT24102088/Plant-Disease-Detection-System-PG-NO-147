{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IT24102088/Plant-Disease-Detection-System-PG-NO-147/blob/main/combined_preprocessing_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Combined Preprocessing Pipeline**"
      ],
      "metadata": {
        "id": "nALqAQcLCKLu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pbTHwXLC0Mib"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "!pip install kaggle\n",
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = 'supuntheekshanam'\n",
        "os.environ['KAGGLE_KEY'] = '97fb6c99381c9d6779d3f904ef279dce'\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d \"vipoooool/new-plant-diseases-dataset\" -p /content/drive/MyDrive/datasets/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upX_FTrE02qF",
        "outputId": "bf640846-5581-44dc-d243-82159e7dae73"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/vipoooool/new-plant-diseases-dataset\n",
            "License(s): copyright-authors\n",
            "Downloading new-plant-diseases-dataset.zip to /content/drive/MyDrive/datasets\n",
            " 99% 2.68G/2.70G [00:41<00:00, 154MB/s]\n",
            "100% 2.70G/2.70G [00:41<00:00, 69.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/datasets/new-plant-diseases-dataset.zip\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "ZKyvu75401Qc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "9u4D4xq-P1-e"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load training and validation data and resize the images**"
      ],
      "metadata": {
        "id": "ZCcCQokBqIvu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "training_set = tf.keras.utils.image_dataset_from_directory(\n",
        "    '/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train/',\n",
        "    image_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    validation_split=None,\n",
        "    subset=None,\n",
        ")\n",
        "\n",
        "training_set = tf.keras.utils.image_dataset_from_directory(\n",
        "    '/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid/',\n",
        "    image_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    validation_split=None,\n",
        "    subset=None,\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJXClOPUP8kA",
        "outputId": "c40a57b2-8e69-47c4-87f8-ece0d389203e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 70295 files belonging to 38 classes.\n",
            "Found 17572 files belonging to 38 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Rescaling**"
      ],
      "metadata": {
        "id": "VrZovLlFrFwX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Rescaling\n",
        "training_set = training_set.map(lambda x, y: (Rescaling(1./255)(x), y))"
      ],
      "metadata": {
        "id": "ymlMOAezQ78v"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Geometric Augmentation**"
      ],
      "metadata": {
        "id": "UAKfjMaArKvm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "geometric_augmentation = tf.keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "    layers.RandomRotation(0.2),\n",
        "    layers.RandomZoom(0.2),\n",
        "    layers.RandomTranslation(0.1, 0.1),\n",
        "])\n",
        "\n",
        "def apply_geometric_augmentation(image, label):\n",
        "    image = geometric_augmentation(image, training=True)\n",
        "    return image, label\n",
        "\n",
        "training_set = training_set.map(apply_geometric_augmentation)\n"
      ],
      "metadata": {
        "id": "Wq9LmqGcQmZA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Color_Augmentation**"
      ],
      "metadata": {
        "id": "0ES3xmZUrV-X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "color_augmentation = tf.keras.Sequential([\n",
        "    layers.RandomBrightness(0.2),\n",
        "    layers.RandomContrast(0.2),\n",
        "    layers.RandomSaturation(0.2),\n",
        "    layers.RandomHue(0.1),\n",
        "])\n",
        "\n",
        "def apply_color_augmentation(image, label):\n",
        "    image = color_augmentation(image, training=True)\n",
        "    return image, label\n",
        "\n",
        "training_set = training_set.map(apply_color_augmentation)"
      ],
      "metadata": {
        "id": "PTuSqyHYRalj"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gaussian Noise**"
      ],
      "metadata": {
        "id": "Hjghcdx-rZHv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import GaussianNoise\n",
        "\n",
        "def add_gaussian_noise(image, stddev=0.05):\n",
        "    noise = tf.random.normal(shape=tf.shape(image), mean=0.0, stddev=stddev)\n",
        "    return tf.clip_by_value(image + noise, 0.0, 1.0)\n",
        "\n",
        "def apply_noise_augmentation(image, label):\n",
        "    image = add_gaussian_noise(image)\n",
        "    return image,label\n",
        "\n",
        "training_set = training_set.map(apply_noise_augmentation)\n",
        "\n"
      ],
      "metadata": {
        "id": "1fvmaNF_RfMG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Histogram Equalization**"
      ],
      "metadata": {
        "id": "SbQ45qBmrhd6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def histogram_equalization_rgb(image):\n",
        "\n",
        "    # Convert to YUV color space\n",
        "    image_yuv = tf.image.rgb_to_yuv(image)\n",
        "\n",
        "    # Apply histogram equalization to Y channel (luminance)\n",
        "    y_channel = image_yuv[..., 0:1]\n",
        "\n",
        "    # Enhanced contrast adjustment (simulating histogram equalization)\n",
        "    y_eq = tf.image.adjust_contrast(y_channel, 2.0)\n",
        "    y_eq = tf.clip_by_value(y_eq, 0.0, 1.0)\n",
        "\n",
        "    # Combine back with original UV channels\n",
        "    image_yuv_eq = tf.concat([y_eq, image_yuv[..., 1:2], image_yuv[..., 2:3]], axis=-1)\n",
        "\n",
        "    # Convert back to RGB\n",
        "    return tf.image.yuv_to_rgb(image_yuv_eq)\n",
        "\n",
        "def apply_histogram_equalization(image, label):\n",
        "    image = histogram_equalization_rgb(image)\n",
        "    return image, label\n",
        "\n",
        "training_set = training_set.map(apply_histogram_equalization)\n",
        "\n"
      ],
      "metadata": {
        "id": "su0wQ4z_RiSs"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}